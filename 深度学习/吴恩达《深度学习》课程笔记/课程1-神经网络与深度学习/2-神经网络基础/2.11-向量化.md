# 向量化

深度学习中有大量特征和数据需要计算，在代码中显式使用循环会使算法很低效。**向量化（Vectorization）** 可以用于解决显式使用循环的问题。

逻辑回归中需要计算：

$$z=w^Tx+b$$

以下是 Python 中向量化和非向量化的实现：

```python
import time
import numpy as np

m = 1000000
a = np.random.rand(m)
b = np.random.rand(m)

# 向量化
start = time.time()
c = np.dot(a, b)
end = time.time()

print(c)
print(f"Vectorized version: {1000 * (end - start)} ms")

# 非向量化
c = 0
start = time.time()
for i in range(m):
    c += a[i] * b[i]
end = time.time()

print(c)
print(f"For loop version: {1000 * (end - start)} ms")

```

输出结果如下所示：

```txt
249545.2225176578
Vectorized version: 1.1529922485351562 ms
249545.22251765372
For loop version: 291.5012836456299 ms
```

向量化有天然并行的语义，可以利用 SIMD（单指令多数据）指令加速，故性能远超循环。
