# 为深度神经网络构建模块

![forward-and-backward-functions](./image/4.5-1.png)


神经网络的一步训练（一个梯度下降循环），包含了从 $a^{[0]}$（即 $x$）经过一系列正向传播计算得到 $\hat{y}$ （即 $a^{[l]}$）。然后再计算 $da^{[l]}$，开始实现反向传播，用链式法则得到所有的导数项，$W$ 和 $b$ 也会在每一层被更新。

在代码实现时，可以将正向传播过程中计算出来的 $z$ 值缓存下来，待到反向传播计算时使用。
