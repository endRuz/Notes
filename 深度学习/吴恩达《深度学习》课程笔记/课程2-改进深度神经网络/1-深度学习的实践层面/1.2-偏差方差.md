# 偏差方差

**偏差-方差分解**（bias-variance decomposition）是解释学习算法泛化性能的一种重要工具。

泛化误差可分解为偏差、方差与噪声之和：

- **偏差**：度量了学习算法的期望预测与真实结果的偏离程度，即刻画了**学习算法本身的拟合能力**；
- **方差**：度量了同样大小的训练集的变动所导致的学习性能的变化，即刻画了**数据扰动所造成的影响**；
- **噪声**：表达了在当前任务上任何学习算法所能够达到的期望泛化误差的下界，即刻画了**学习问题本身的难度**。

偏差-方差分解说明，**泛化性能**是由**学习算法的能力**、**数据的充分性**以及**学习任务本身的难度**所共同决定的。给定学习任务，为了取得好的泛化性能，则需要使偏差较小，即能够充分拟合数据，并且使方差较小，即使得数据扰动产生的影响小。

下图为一个只有和两个特征的二维数据集中，我们可以绘制数据，将偏差和方差可视化：

![](./image/1.2-1.png)

下面第一个图中数据集拟合一条直线，但它并不能很好地拟合该数据，这是 **高偏差（high bias）** 的情况，我们称为 **欠拟合（underfitting）**。

第三个图中拟合一个非常复杂的分类器，可能就非常适用于这个数据集，但是这看起来也不是一种很好的拟合方式，分类器 **高方差（high variance）**，数据 **过拟合（overfitting）**。

第二个图这样的，复杂程度适中，数据拟合适度的分类器，这个数据拟合看起来更加合理，我们称之为 **适度拟合（just right）** 是介于过拟合和欠拟合中间的一类。

![](./image/1.2-2.png)

在数据集拥有多个特征时，可以通过 **训练集误差（Train set error）** 和 **验证集误差（Dev set error）** 两个指标来研究偏差和方差。

| 训练集误差 | 验证集误差 | 偏差 | 方差 | |
| :-: | :-: |  :- |:-: | :-: |
| 1% | 11% | 低 | 高 | 过拟合 |
| 15% | 16% | 高 | 低 | 欠拟合 |
| 15% | 30% | 高 | 高 | 过拟合、欠拟合 |
| 0.5% | 1% | 低 | 低 | 适度拟合 |

以上分析都是基于假设预测的，假设人眼辨别的错误率接近 0%。一般来说，**最优误差** 也被称为 **贝叶斯误差**，所以，最优误差接近 0%。

如果最优误差或贝叶斯误差非常高，比如 15%。我们再看看这个分类器（训练误差 15%，验证误差 16%），15% 的错误率对训练集来说也是非常合理的，偏差不高，方差也非常低。

自我总结（不一定对）：

- **偏差**指的是训练集误差和贝叶斯误差的差距，**高偏差** 就是 **欠拟合**；
- **方差**指的是训练集误差和验证集误差的差距，**高方差** 就是 **过拟合**。
