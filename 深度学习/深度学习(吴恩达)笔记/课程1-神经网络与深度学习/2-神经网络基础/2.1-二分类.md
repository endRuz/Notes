# 二分类

实现一个神经网络时，如果需要遍历整个训练集，并不需要直接使用 for 循环。

神经网络的计算过程中，通常有一个 **正向过程（forward pass）** 或者叫 **正向传播（forward propagation）** 的步骤，接着会有一个 **反向过程（backward pass）** 或者叫 **反向传播（backward propagation）** 的步骤。

本节课以 **逻辑回归（logistic regression）** 为例来进行讲解，逻辑回归是一个 **二分类（Binary Classification）** 算法。

二分类例子：以一张图片作为输入，识别是否为猫，若为猫则返回 $1$，若不为则返回 $0$。

使用 $y$ 来表示输出的结果。

![二分类](./image/2.1-1.png)

（彩色）图片在计算机中的表示：若有一个 $64 \times 64$ 像素大小的图片，则需要保存三个 $64 \times 64$ 的矩阵来分别对应图片的红、绿、蓝三种颜色通道。

![（彩色）图片在计算机中的表示](./image/2.1-2.png)

图片转换为特征向量 $x$：按照 RGB 的顺序依次把所有像素都取出来得到一个特征向量，特征向量的维度为是三个像素矩阵中像素的总量。

例子中特征向量维度为 $64 \times 64 \times 3 = 12288$，用 $n_x = 12288$ 表示。有时会简化为 $n$ 来表示特征向量维度。

![图片转换为特征向量](./image/2.1-3.png)

所以在二分类问题中，我们的目标就是习得一个分类器，它以图片的特征向量 $x$ 作为输入，然后预测输出结果 $y$ 为 $1$ 还是 $0$。

符号定义：

- $(x, y)$ 表示一组单独的数据
- $x$ 表示一个 $n_x$ 维的特征向量
- $y$ 表示输出结果，取值为 $(0, 1)$
- $m$ 表示数据集的数据总数
- $m_{train}$ 表示训练集的数据总数
- $m_{test}$ 表示测试集的数据总数
- $(x^{(i)}, y^{(i)})$ 表示第 $i$ 组数据
- $X = [x^{(1)}, x^{(2)}, \cdots , x^{(m)}]$ 表示所有训练数据集的输入值，维度为 $n_x \times m$
- $Y = [y^{(1)}, y^{(2)}, \cdots , y^{(m)}]$ 表示所有训练数据集的输出值，维度为 $1 \times m$
