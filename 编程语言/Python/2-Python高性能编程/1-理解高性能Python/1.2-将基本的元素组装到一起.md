# 将基本的元素组装到一起

- [将基本的元素组装到一起](#将基本的元素组装到一起)
  - [理想计算模型](#理想计算模型)
  - [Python 虚拟机](#python-虚拟机)
  - [总结](#总结)

为了更好地理解高性能编程的要素，让我们来看一段用于判断质数的简单代码样例：

```python
import math

def check_prime(number):
    sqrt_number = math.sqrt(number)
    number_float = float(number)
    for i in xrange(2, int(sqrt_number)+1):
        if (number_float / i).is_integer():
            return False
    return True

print "check_prime(10000000) = ", check_prime(10000000) # False
print "check_prime(10000019) = ", check_prime(10000019) # True
```

## 理想计算模型

在代码的开头，我们将 number 的值保存于 RAM 中。为了计算 sqrt_number 和 number_float，我们需要将该值传入 CPU。在理想情况下，我们只需要传一次，它将被保存在 CPU 的 L1/L2 缓存中，然后 CPU 会进行两次计算并将结果传回 RAM 保存。这是一个理想的情况，因为我们令从 RAM 中读取 number 的值的次数最少，转而以快很多的 L1/L2 缓存的读取代替。另外，我们还令前端总线传输数据的次数最少，以更快的后端总线（连接 CPU 和各类缓存）的传输代替之。将数据保持在需要的地方并尽量少移动这一场景对于优化来说至关重要。所谓“沉重数据”的概念指的是移动数据需要花费时间，而这就是我们需要避免的。

在代码的循环部分，与其一次次将 i 输入 CPU，我们更希望一次就将 number_float 和多个 i 的值输入 CPU 进行检查。这是可能的，因为 CPU 的矢量操作不需要额外的时间代价，意味着它可以一次进行多个独立计算。所以我们希望将 number_float 传入 CPU 缓存，以及在缓存放得下的情况下传入尽可能多的 i 的值。对于每一对 number_float/i，我们将进行除法计算并检查结果是否为整数，然后传回一个信号表明是否有任意一个结果确实为整数。如果是，则函数结束。如果否，我们继续下一批计算。这样，对于多个 i 的值，我们只需要传回一个结果，而不是依靠总线返回所有的值。这利用了 CPU 的矢量化计算的能力，或者说在一个时钟周期内以一条指令操作了多个数据。

这一矢量操作的概念可以用下列代码来表述：

```python
import math

def check_prime(number):
    sqrt_number = math.sqrt(number)
    number_float = float(number)
    numbers = range(2, int(sqrt_number)+1)
    for i in xrange(0, len(numbers), 5):
        # the following line is not valid Python code
        result = (number_float / numbers[i:(i+5)]).is_integer()
        if any(result):
            return False
    return True
```

这里，我们让程序一次对 5 个 i 的值进行除法和整数检查。当被正确地矢量化时，CPU 仅需一条指令完成这行代码而不是对每个 i 进行独立操作。理想情况下，any(result) 操作将只发生于 CPU 内部而无须将数据传回 RAM。

## Python 虚拟机

Python 解释器为了抽离底层用到的计算元素做了很多工作。这让编程人员无须考虑如何为数组分配内存、如何组织内存以及用什么样的顺序将内存传入 CPU。这是 Python 的一个优势，让你能够集中在算法的实现上。然而它有一个巨大的性能代价。

而 Python 虚拟机抽象层的影响之一就是矢量操作变得不是直接可用了。我们最初的质数函数会循环遍历 i 的每一个值而不是将多次遍历组合成一个矢量操作。而我们抽象以后的矢量化代码并不是合法的 Python 代码，因为我们不能用一个列表去除一个浮点。numpy 这样的外部库可以通过增加矢量化数学操作的方式帮助我们解决这个问题。

另外，Python 抽象还影响了任何需要为下一次计算保存 L1/L2 缓存中相关数据的优化。这有很多原因，首先是 Python 对象不再是内存中最优化的布局。这是因为 Python 是一种垃圾回收语言——内存会被自动分配并在需要时释放。这会导致内存碎片并影响向 CPU 缓存的传输。另外，我们也没有任何机会去直接改变数据结构在内存中的布局，这意味着总线上的一次传输可能并不包含一次计算的所有相关信息，即使这些信息少于总线带宽。

第二个问题更加基本，根源是 Python 的动态类型以及 Python 并不是一门编译性的语言。很多 C 语言开发者已经在多年开发过程中意识到，编译器总是比你聪明。当编译静态代码时，编译器可以做很多的事情来改变对象的内存布局以及让 CPU 运行某些指令来优化它们。然而，Python 并不是一种编译性的语言：更糟的是，它还具有动态类型，意味着任何算法上可能的优化机会都会更加难以实现，因为代码的功能有可能在运行时被改变。有很多方法可以缓解这一问题，其中最主要的一个方法就是使用 Cython，它可以将 Python 代码进行编译并允许用户“提示”编译器代码究竟有多“动态”。

最后，之前提到的 GIL 会影响并行代码的性能。比如，假设我们改变代码来使用多个 CPU 核心，每个核心收到一堆数字，取值范围是 2 到 sqrtN。每个核心可以对自身收到的数据进行计算，当它们都完成时可以互相进行比较。这看上去是一个好方案，虽然我们失去了提前中止循环的能力，但是随着我们使用的核心数的增加，每个核心需要进行的检查数降低了（例如，如果我们有 M 个核心，每个核心只需要进行 sqrtN/M 次检查）。然而，由于 GIL，一次仅有一个核心可以被使用。这意味着我们还是以非并行的方式运行这段代码，而且还不能提前中止。我们可以使用多进程（multiprocessing 模块）而不是多线程，或者使用 Cython 或外部函数来避免这个问题。

## 总结

实现高性能 Python 代码的障碍：

1. 矢量操作不可用
2. 垃圾回收机制
3. 动态类型
4. GIL
