# 基本的计算机系统

- [基本的计算机系统](#基本的计算机系统)
  - [计算单元](#计算单元)
  - [存储单元](#存储单元)
  - [通信层](#通信层)

一台计算机的底层组件可被分为三大基本部分：

- 计算单元（CPU, GPU ...）
- 存储单元（内存 RAM, 硬盘 ...）
- 计算单元和存储单元之间的连接（总线, 网络连接 ...）

这些单元还具有多种属性帮助我们了解它们：

- 计算单元有一个属性告诉我们它每秒能够进行多少次计算
- 存储单元有一个属性告诉我们它能保存多少数据
- 存储单元还有一个属性告诉我们能以多快的速度对它进行读写
- 连接有一个属性告诉我们它们能以多快的速度将数据从一个地方移动到另一个地方

## 计算单元

一台计算机的计算单元是其中央部件——它具有将接收到的任意输入转换成输出的能力以及改变当前处理状态的能力。

计算单元的主要属性如下：

- 每个周期能进行的操作数量
- 每秒能完成多少个周期

以上两个属性分别通过以下两个指标进行衡量：

- 每周期完成的指令数（IPC）（不要跟进程间通信（也是 IPC）混淆）
- 时钟速度

提高钟速度能够立即提高该计算单元上所有的程序运行速度（因为它们每秒能进行更多运算）;

提高 IPC 则在矢量计算能力上有相当程度的影响。

> 矢量计算是指一次提供多个数据给一个 CPU 并能同时被操作。这种类型的 CPU 指令被称为 SIMD（单指令多数据）。

计算单元在过去十年的进展颇为有限。时钟速度和 IPC 的提升都限于停滞，因为晶体管已经小到了物理的极限。结果就是芯片制造商开始依靠其他手段来获得更高的速度，包括超线程技术，更聪明的乱序执行和多核架构。

1. 超线程技术为主机的操作系统（OS）虚拟了第二个 CPU，而聪明的硬件逻辑则试图将两个指令线程交错地插入单个 CPU 的执行单元。如果成功插入，能比单线程提升 30%。一般来讲，当两个线程的工作分布在不同的执行单元上时，这样做效果不错——比如一个操作浮点而另一个操作整数时。

2. 乱序执行允许编译器检测出一个线性程序中某部分可以不依赖于之前的工作，也就是说两个工作能够以各种顺序执行或同时执行。只要两个工作的成果都能够在正确的时间点上依次得到，哪怕它们的计算次序跟程序设计不同，程序也能继续正确运行。这使得当一些指令被阻塞时（比如等待一次内存访问），另一些指令得以执行，以此来提升资源的利用率。

3. 最后也是对于高级程序员来说最重要的是多核架构的普及。这些架构在同一个计算单元中包含了多个 CPU，提高了总体计算能力，而且无须等待内存屏障，让单个核心可以跑得更快。这就是为什么现在已经很难找到少于双核的计算机了——双核意味着计算机有两个互连的物理计算单元。虽然这增加了每秒可以进行的操作总数，但是想要让两个计算单元都达到最大利用率的话还需要考虑很多错综复杂的因素。

给 CPU 增加更多的核心并不一定能提升程序运行的速度。这是由阿姆达尔定律决定的。简单地说，阿姆达尔定律认为如果一个可以运行在多核上的程序有某些执行路径必须运行在单核上，那么这些路径就会成为瓶颈导致最终速度无法通过增加更多核心来提高。

另外，对于 Python 来说，充分利用多核性能的阻碍主要在于 Python 的全局解释器锁（GIL）。GIL 确保 Python 进程一次只能执行一条指令，无论当前有多少个核心。这意味着即使某些 Python 代码可以使用多个核心，在任意时间点仅有一个核心在执行 Python 的指令。以前面调查的例子来说，即使我们有 100 位提问者，然而一次仅有一位可以提问和接受回答，并没有什么用！这看上去是个严重的阻碍，特别是当现在计算机发展的趋势就是拥有更多而非更快的计算单元的时候。好在这个问题其实可以通过一些方法来避免，比如标准库的 multiprocessing，或 numexpr、Cython 等技术，或分布式计算模型等。

## 存储单元

存储单元的主要属性：

- 读写速度
- 延时的属性：表示了设备为了查找到需要的数据所花费的时间

更复杂的问题在于，存储单元读写数据的速度还与数据的读写方式息息相关。

比如，大多数存储单元一次读一大块数据的性能远好于读多次小块数据（顺序读取 VS 随机数据）。将这些存储单元中的数据想象成一本书中的书页，大多数存储单元的读写速度在连续翻页时高于经常从一张随机页跳至另一张随机页。所有的存储单元或多或少都受到这一影响，但不同类型存储单元受到的影响却大不相同。

下面是一个标准工作站内常见的各类存储单元的简短描述，以读写速度排序：

1. 旋转硬盘：计算机关机也能保持的长期存储。读写速度通常较慢，因为磁盘必须物理旋转和等待磁头移动。随机访问性能下降但容量很高（TB 级别）。
2. 固态硬盘：类似旋转硬盘，读写速度较快但容量较小（GB 级别）。
3. RAM：用于保存应用程序的代码和数据（比如用到的各种变量）。具有更快的读写速度且在随机访问时性能良好，但通常受限于容量（GB 级别）。
4. L1/L2 缓存：极快的读写速度。进入 CPU 的数据必须经过这里。很小的容量（KB 级别）

一个清晰可见的趋势是读写速度和容量成反比——当我们试图加快速度时，容量就下降了。因此，很多系统都实现了一个分层的存储：数据一开始都在硬盘里，部分进入 RAM，然后很小的一个子集进入 L1/L2 缓存。这种分层使得程序可以根据访问速度的需求将数据保存在不同的地方。

在试图优化程序的存储访问模式时，我们只是简单优化了数据存放的位置、布局（为了增加顺序读取的次数），以及数据在不同位置之间移动的次数。另外，异步 I/O 和缓存预取等技术还提供了很多方法来确保数据在被需要时就已经存在于对应的地方而不需要浪费额外的计算时间——这些过程可以在进行其他计算时独立进行！

## 通信层

通信有很多模式，但它们都是同一样东西的变种：总线。

一条总线的主要属性是它的速度：在给定时间内它能传输多少数据。该属性由两个因素决定：

1. 总线带宽：一次能传输多少数据
2. 总线频率：每秒能传输几次

需要说明的是一次传输的数据总是有序的：一块数据先从内存中读出，然后被移动到另一个地方。这就是为什么总线的速度可以被拆分为两个因素，因为这两个因素分别独立影响计算的不同方面：高的总线带宽可以一次性移动所有相关数据，有助于矢量化的代码（或任何顺序读取内存的代码），而另一方面，低带宽高频率有助于那些经常随机读取内存的代码。有意思的是，这些属性是由计算机设计者在主板的物理布局上决定的：当芯片之间相距较近时，它们之间的物理链路就较短，就可以允许更高的传输速度。而物理链路的数量则决定了总线的带宽（带宽这个词真的具有物理上的意义！）。

由于物理接口可以针对某个特定应用优化，所以我们不会奇怪世上存在成百上千种不同类型的连接。图 1-3 显示了一些常见接口的比特率。注意这图上完全没提到连接的延时，延时决定了一个连接响应数据请求花费的时间（虽然延时跟具体的计算机系统息息相关，但是有来自物理接口的一些基本限制）
